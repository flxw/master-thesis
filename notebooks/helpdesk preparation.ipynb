{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "import copy\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from prefixspan import PrefixSpan\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### configuration\n",
    "data_path = \"../logs/helpdesk.csv\"\n",
    "traces_picklepath  = data_path.replace(\".csv\", \"_raw_traces.pickled\")\n",
    "traces_dictionarypath = data_path.replace(\".csv\", \"_dictionaries.pickled\")\n",
    "target_column = \"concept:name\"\n",
    "categorical_feature_names = [target_column]\n",
    "date_feature_names = [\"time:timestamp\"]\n",
    "eosmarker = \"<EOS>\"\n",
    "ncores = multiprocessing.cpu_count()\n",
    "### configuration end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data trace-wise from CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog = pd.read_csv(data_path).sort_values(by=['CaseID', 'CompleteTimestamp'])\n",
    "\n",
    "traces = []\n",
    "for _, g in eventlog.groupby(eventlog['CaseID']):\n",
    "    g = g[['ActivityID', 'CompleteTimestamp']].reset_index(drop=True)\n",
    "    g['ActivityID'] = g['ActivityID'].astype(str)\n",
    "    g = g.rename(columns={'ActivityID': 'concept:name', 'CompleteTimestamp': 'time:timestamp'})\n",
    "    traces.append(g)\n",
    "\n",
    "pickle.dump(traces, open(traces_picklepath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = pickle.load(open(traces_picklepath, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert timestamps to relative scale in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to total running time in hours\n",
    "bos_idx = 0\n",
    "for i in range(0, len(traces)):    \n",
    "    for c in [\"time:timestamp\"]:\n",
    "        traces[i][c] = pd.to_datetime(traces[i][c], utc=True)\n",
    "        dfs = traces[i][c] - traces[i][c][bos_idx]\n",
    "        traces[i][c] = dfs.map(lambda d: int(d.total_seconds()/(60*60))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog_df = pd.concat(traces, ignore_index=True)\n",
    "feature_dict = {}\n",
    "for cf in categorical_feature_names:\n",
    "    cf_dict = { 'to_int': {}, 'to_cat': {} }\n",
    "    events = eventlog_df[cf].unique().tolist()\n",
    "    if cf == target_column: events.append(eosmarker)\n",
    "    cf_dict['to_int'] = dict((c, i) for i, c in enumerate(events))\n",
    "    cf_dict['to_cat'] = dict((i, c) for i, c in enumerate(events))\n",
    "    feature_dict[cf] = cf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SP2 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f59649c7a3d4472a8f99e803fbfac5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3804), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through every trace and encode the presence of an activity\n",
    "sp2_prefix = \"SP2_\"\n",
    "activity_labels = [ \"{0}{1}\".format(sp2_prefix,a) for a in eventlog_df[target_column].unique() ]\n",
    "\n",
    "def enrich_trace_with_sp2(t):\n",
    "    sp2_df = pd.DataFrame(columns=activity_labels, index=range(0,len(t)), dtype=np.bool)\n",
    "    for col in sp2_df.columns: sp2_df[col].values[:] = 0\n",
    "    sp2_df[\"{0}{1}\".format(sp2_prefix, t[target_column][0])].values[0]  = 1\n",
    "    \n",
    "    for i in range(1,len(t)):\n",
    "        first_activity_name = t[target_column].iloc[i]\n",
    "        col = \"{0}{1}\".format(sp2_prefix,first_activity_name)\n",
    "        \n",
    "        sp2_df.values[i] = sp2_df.values[i-1]\n",
    "        sp2_df[col].values[i] = 1\n",
    "        \n",
    "    return sp2_df\n",
    "\n",
    "ppool = multiprocessing.Pool(ncores)\n",
    "sp2_traces = []\n",
    "\n",
    "for _ in tqdm_notebook(ppool.imap(enrich_trace_with_sp2, traces),\n",
    "                       total=len(traces),\n",
    "                       unit=\"traces\"):\n",
    "        sp2_traces.append(_)\n",
    "        \n",
    "ppool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PrefixSpan feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixspan requires an array of arrays with one subarray for every trace\n",
    "encoded_traces = [ t[target_column].map(feature_dict[target_column]['to_int']).tolist() for t in traces ]\n",
    "prefixspan_traces = PrefixSpan(encoded_traces)\n",
    "closed_sequences = prefixspan_traces.topk(25, closed=True) # support is how often the subsequence appears in total\n",
    "# http://sequenceanalysis.github.io/slides/analyzing_sequential_user_behavior_part2.pdf, slide 5\n",
    "\n",
    "# only take subsequence which are at a certain level of support? like if ss[0]/len(traces) < .90\n",
    "#ps_topkc = list(filter(lambda x: x[0]/len(traces) > .90, ps_topkc))\n",
    "closed_sequences = [ p[1] for p in closed_sequences ]\n",
    "pftrace_args = [ (t, closed_sequences[:], feature_dict[target_column]['to_int']) for t in traces ] # enrich traces with copy of mined subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abb2ce84d984032986b978c8e39c6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3804), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def wrapped__enrich_trace_with_subseq(args):\n",
    "    return enrich_trace_with_subseq(*args)\n",
    "\n",
    "def enrich_trace_with_subseq(t, ps, event_to_int):\n",
    "    col_prefix = \"PFS_\"\n",
    "    subseq_labels = [ \"{0}{1}\".format(col_prefix,ss_idx) for ss_idx, ss in enumerate(ps) ]\n",
    "    subseq_df = pd.DataFrame(columns=subseq_labels, index=range(0,len(t)), dtype=np.bool)\n",
    "    \n",
    "    subseq_df[:].values[:] = False\n",
    "    activity_codes = t[\"concept:name\"].map(event_to_int)\n",
    "    tlen = len(t)\n",
    "    \n",
    "    for i in range(0, tlen):\n",
    "        # loop through all subsequences\n",
    "        for subseq_idx, subseq in enumerate(ps):\n",
    "            if tlen <= i+len(subseq):\n",
    "                continue\n",
    "                \n",
    "            # check if the subsequence takes place in the following fields\n",
    "            subsequence_found = True\n",
    "            j = 0\n",
    "            while subsequence_found and j < len(subseq):\n",
    "                if subseq[j] != activity_codes[j+i]:\n",
    "                    subsequence_found = False\n",
    "                j += 1\n",
    "                    \n",
    "            if subsequence_found:\n",
    "                subseq_df.values[i+j-1:,subseq_idx] = True\n",
    "        \n",
    "    return subseq_df\n",
    "\n",
    "ppool = multiprocessing.Pool(ncores)\n",
    "pf_traces = []\n",
    "        \n",
    "for _ in tqdm_notebook(ppool.imap(wrapped__enrich_trace_with_subseq, pftrace_args),\n",
    "                       total=len(pftrace_args),\n",
    "                       unit=\"traces\"):\n",
    "        pf_traces.append(_)\n",
    "        \n",
    "ppool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and normalize ordinal and categorical feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_feature_names = traces[0].columns.difference(categorical_feature_names)\n",
    "n_target_classes = max(feature_dict[target_column]['to_int'].values()) + 1\n",
    "final_traces = copy.deepcopy(traces)\n",
    "\n",
    "ordinal_traces = [None] * len(traces)\n",
    "categorical_traces = [None] * len(traces)\n",
    "target_traces = [None] * len(traces)\n",
    "\n",
    "# Concatenate all features into one feature dataframe per trace\n",
    "for i in range(0, len(traces)):\n",
    "    \n",
    "    # Create TARGET feature column by shifting target column\n",
    "    targets = final_traces[i][target_column].shift(-1).map(feature_dict[target_column]['to_int']).to_frame(\"TARGET\")\n",
    "    targets.values[len(targets)-1] = feature_dict[target_column]['to_int'][eosmarker]\n",
    "    target_traces[i] = pd.DataFrame(np_utils.to_categorical(targets, num_classes=n_target_classes, dtype='bool')).add_prefix(\"TARGET_\")\n",
    "    \n",
    "    # Create separate dfs for ordinal and categorical traces\n",
    "    ordinal_traces[i] = final_traces[i][ordinal_feature_names].astype(np.float32)\n",
    "    categorical_traces[i] = final_traces[i][categorical_feature_names].astype(np.str)\n",
    "    \n",
    "    # min-max-normalization of ordinal features PER TRACE\n",
    "    assert len(ordinal_traces[i]) == len(traces[i]), i\n",
    "    x = ordinal_traces[i]\n",
    "    denominator = x.max(axis=0) - x.min(axis=0)\n",
    "    \n",
    "    for j in range(0, len(denominator)):\n",
    "        if(denominator[j] == 0):\n",
    "            denominator[j] += 1\n",
    "            \n",
    "    ordinal_traces[i] = (x-x.min(axis=0)) / denominator\n",
    "    assert len(ordinal_traces[i]) == len(traces[i]), i\n",
    "    \n",
    "del final_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sava data sets per variable type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indices for stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = list(range(len(ordinal_traces)))\n",
    "y = [len(t) for t in ordinal_traces]\n",
    "train_indices, test_indices, _, _ = train_test_split(X,y, test_size=0.25, random_state=42)\n",
    "\n",
    "save_path = \"/home/felix.wolff2/master-thesis-code/logs/helpdesk/\"\n",
    "def save_trace_dataset(dataset, settype, purpose):\n",
    "    suffix = \"{0}_{1}.pickled\".format(settype, purpose)\n",
    "    p = save_path + suffix\n",
    "    pickle.dump(dataset, open(p, \"wb\"), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "def filter_by_indices(a, a_idx):\n",
    "    return [ a[i] for i in range(len(a)) if i in a_idx ]\n",
    "\n",
    "save_trace_dataset(feature_dict, 'mapping', 'dict')\n",
    "save_trace_dataset(filter_by_indices(ordinal_traces, train_indices), 'ordinal', 'train')\n",
    "save_trace_dataset(filter_by_indices(categorical_traces, train_indices), 'categorical', 'train')\n",
    "save_trace_dataset(filter_by_indices(sp2_traces, train_indices), 'sp2', 'train')\n",
    "save_trace_dataset(filter_by_indices(pf_traces, train_indices), 'pfs', 'train')\n",
    "save_trace_dataset(filter_by_indices(target_traces, train_indices),'target', 'train')\n",
    "save_trace_dataset(filter_by_indices(ordinal_traces, test_indices), 'ordinal', 'test')\n",
    "save_trace_dataset(filter_by_indices(categorical_traces, test_indices), 'categorical', 'test')\n",
    "save_trace_dataset(filter_by_indices(sp2_traces, test_indices), 'sp2', 'test')\n",
    "save_trace_dataset(filter_by_indices(pf_traces, test_indices), 'pfs', 'test')\n",
    "save_trace_dataset(filter_by_indices(target_traces, test_indices),'target', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min trace length 1\n",
      "Max trace length 14\n",
      "Avg trace length 3.6041009463722395\n",
      "Std trace length 1.1874492656422815\n",
      "# traces 3804\n",
      "Number of events 13710\n",
      "Number of activities 9\n"
     ]
    }
   ],
   "source": [
    "lens = [len(t) for t in traces]\n",
    "print(\"Min trace length\", min(lens))\n",
    "print(\"Max trace length\", max(lens))\n",
    "print(\"Avg trace length\", np.mean(lens))\n",
    "print(\"Std trace length\", np.std(lens))\n",
    "print(\"# traces\", len(traces))\n",
    "print(\"Number of events\", sum(lens))\n",
    "print(\"Number of activities\", len(eventlog_df[target_column].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis feature examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    8\n",
       "2    6\n",
       "3    8\n",
       "4    6\n",
       "Name: concept:name, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces[3][\"concept:name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP2_1</th>\n",
       "      <th>SP2_8</th>\n",
       "      <th>SP2_6</th>\n",
       "      <th>SP2_3</th>\n",
       "      <th>SP2_9</th>\n",
       "      <th>SP2_2</th>\n",
       "      <th>SP2_4</th>\n",
       "      <th>SP2_5</th>\n",
       "      <th>SP2_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SP2_1  SP2_8  SP2_6  SP2_3  SP2_9  SP2_2  SP2_4  SP2_5  SP2_7\n",
       "0   True  False  False  False  False  False  False  False  False\n",
       "1   True   True  False  False  False  False  False  False  False\n",
       "2   True   True   True  False  False  False  False  False  False\n",
       "3   True   True   True  False  False  False  False  False  False\n",
       "4   True   True   True  False  False  False  False  False  False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2_traces[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PFS_0</th>\n",
       "      <th>PFS_1</th>\n",
       "      <th>PFS_2</th>\n",
       "      <th>PFS_3</th>\n",
       "      <th>PFS_4</th>\n",
       "      <th>PFS_5</th>\n",
       "      <th>PFS_6</th>\n",
       "      <th>PFS_7</th>\n",
       "      <th>PFS_8</th>\n",
       "      <th>PFS_9</th>\n",
       "      <th>...</th>\n",
       "      <th>PFS_15</th>\n",
       "      <th>PFS_16</th>\n",
       "      <th>PFS_17</th>\n",
       "      <th>PFS_18</th>\n",
       "      <th>PFS_19</th>\n",
       "      <th>PFS_20</th>\n",
       "      <th>PFS_21</th>\n",
       "      <th>PFS_22</th>\n",
       "      <th>PFS_23</th>\n",
       "      <th>PFS_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PFS_0  PFS_1  PFS_2  PFS_3  PFS_4  PFS_5  PFS_6  PFS_7  PFS_8  PFS_9  \\\n",
       "0  False  False  False  False  False  False  False  False  False  False   \n",
       "1  False  False  False  False  False  False  False  False  False  False   \n",
       "2   True  False   True   True  False  False  False  False  False  False   \n",
       "3   True  False   True   True  False  False  False  False  False  False   \n",
       "4   True  False   True   True  False  False  False  False  False  False   \n",
       "\n",
       "    ...    PFS_15  PFS_16  PFS_17  PFS_18  PFS_19  PFS_20  PFS_21  PFS_22  \\\n",
       "0   ...     False   False   False   False   False   False   False   False   \n",
       "1   ...     False   False   False   False   False   False   False   False   \n",
       "2   ...     False   False   False   False   False   False   False   False   \n",
       "3   ...     False   False   False   False   False   False   False   False   \n",
       "4   ...     False   False   False   False   False   False   False   False   \n",
       "\n",
       "   PFS_23  PFS_24  \n",
       "0   False   False  \n",
       "1   False   False  \n",
       "2   False   False  \n",
       "3   False   False  \n",
       "4   False   False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_traces[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6'], ['1', '6'], ['8', '6'], ['1', '8', '6'], ['9', '6']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: list(map(lambda xx: feature_dict[\"concept:name\"][\"to_cat\"][xx], x)), closed_sequences[:5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
