{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from opyenxes.model.XLog import XLog\n",
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "from opyenxes.classification.XEventAttributeClassifier import XEventAttributeClassifier\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import LSTM\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown extension: http://www.xes-standard.org/meta_time.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_life.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_org.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_concept.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_3TU.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_general.xesext\n"
     ]
    }
   ],
   "source": [
    "bpic_2011_path = \"master-thesis/logs/bpic2011.xes\"\n",
    "\n",
    "with open(bpic_2011_path) as bpic2011_file:\n",
    "    bpic2011_log = XUniversalParser().parse(bpic2011_file)[0]\n",
    "\n",
    "raw_trace = bpic2011_log[0]\n",
    "raw_event = raw_trace[0]\n",
    "raw_attributes = raw_event.get_attributes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_traces = [[ ev.get_attributes()[\"concept:name\"].get_value() for ev in trace ] for trace in bpic2011_log ]\n",
    "event_traces = list(itertools.chain.from_iterable(event_traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 150291\n",
      "Total number of event types: 624\n"
     ]
    }
   ],
   "source": [
    "events = sorted(list(set(event_traces)))\n",
    "event_to_int = dict((c, i) for i, c in enumerate(events))\n",
    "\n",
    "n_events = len(event_traces)\n",
    "n_vocab = len(events)\n",
    "\n",
    "print(\"Total events:\", n_events)\n",
    "print(\"Total number of event types:\", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 150286\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 5\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_events - seq_length, 1):\n",
    "    seq_in  = event_traces[i:i + seq_length]\n",
    "    seq_out = event_traces[i + seq_length]\n",
    "    dataX.append([event_to_int[ev] for ev in seq_in])\n",
    "    dataY.append(event_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = keras.utils.np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 21760/150286 [===>..........................] - ETA: 2:10 - loss: 4.4143"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=2, batch_size=128, callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
