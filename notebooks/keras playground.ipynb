{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opyenxes.model.XLog import XLog\n",
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "from opyenxes.classification.XEventAttributeClassifier import XEventAttributeClassifier\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "#from keras.layers import LSTM\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpic_2011_path = \"../logs/bpic2011.xes\"\n",
    "\n",
    "with open(bpic_2011_path) as bpic2011_file:\n",
    "    bpic2011_log = XUniversalParser().parse(bpic2011_file)[0]\n",
    "\n",
    "raw_trace = bpic2011_log[0]\n",
    "raw_event = raw_trace[0]\n",
    "raw_attributes = raw_event.get_attributes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_traces = [[ ev.get_attributes()[\"concept:name\"].get_value() for ev in trace ] for trace in bpic2011_log ]\n",
    "event_traces = list(itertools.chain.from_iterable(event_traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = sorted(list(set(event_traces)))\n",
    "event_to_int = dict((c, i) for i, c in enumerate(events))\n",
    "int_to_event = dict((i,c) for i,c in enumerate(events))\n",
    "\n",
    "n_events = len(event_traces)\n",
    "n_vocab = len(events)\n",
    "\n",
    "print(\"Total events:\", n_events)\n",
    "print(\"Total number of event types:\", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 5\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_events - seq_length, 1):\n",
    "    seq_in  = event_traces[i:i + seq_length]\n",
    "    seq_out = event_traces[i + seq_length]\n",
    "    dataX.append([event_to_int[ev] for ev in seq_in])\n",
    "    dataY.append(event_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = keras.utils.np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=2, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = \"weights-improvement-02-3.3127.hdf5\"\n",
    "model.load_weights(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = [ np.argmax(p) for p in prediction ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([prediction_index[i] == dataY[i] for i in prediction_index]) / len(prediction_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prefixspan here\n",
    "from prefixspan import PrefixSpan\n",
    "\n",
    "event_sequences = [[ ev.get_attributes()[\"concept:name\"].get_value() for ev in trace ] for trace in bpic2011_log ]\n",
    "translated_sequences = [ [event_to_int[ev] for ev in trace] for trace in event_sequences]\n",
    "\n",
    "ps = PrefixSpan(translated_sequences)\n",
    "\n",
    "print(ps.frequent(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
