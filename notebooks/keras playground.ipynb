{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "from tqdm import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Input, Reshape, concatenate, Flatten, Activation, LSTM\n",
    "from keras.utils  import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CONFIGURATION SETUP ####\n",
    "\n",
    "data_path = \"../logs/bpic2011.xes\"\n",
    "traces_finalpath = data_path.replace(\".xes\", \"_traces_encoded.pickled\")\n",
    "traces_dictionarypath = data_path.replace(\".xes\", \"_dictionaries.pickled\")\n",
    "n_sp2_features = 624\n",
    "n_pfs_features = 25\n",
    "\n",
    "traces = pickle.load(open(traces_finalpath, \"rb\"))\n",
    "feature_dict = pickle.load(open(traces_dictionarypath, \"rb\"))\n",
    "\n",
    "### CONFIGURATION SETUP END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle complete traces and create test and training set\n",
    "random.shuffle(traces)\n",
    "sep_idx = int(0.8*len(traces))\n",
    "\n",
    "# extract the feature indices\n",
    "# data is organized like this: ordinal features | categorical features | SP2 features | PFS features | TARGET features\n",
    "# needed as every of these features will get its own layer\n",
    "feature_names  = traces[0].columns\n",
    "trace_columns = list(map(lambda e: bool(re.match('^TARGET$', e)), feature_names))\n",
    "target_col_start_index = trace_columns.index(True)\n",
    "\n",
    "categorical_feature_names = feature_dict.keys()\n",
    "pfs_col_start_index = target_col_start_index - n_pfs_features\n",
    "sp2_col_start_index = pfs_col_start_index - n_sp2_features\n",
    "cat_col_start_index = sp2_col_start_index - len(categorical_feature_names)\n",
    "\n",
    "ordinal_feature_names     = feature_names[0:cat_col_start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_name(var_name):\n",
    "    return \"input_{0}\".format(''.join(c for c in var_name if c.isalnum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting traces to Keras learning data:   0%|          | 0/914 [00:00<?, ?traces/s]\n",
      "Converting traces to Keras learning data:   0%|          | 1/914 [00:00<02:22,  6.43traces/s]\n",
      "Converting traces to Keras learning data:   0%|          | 2/914 [00:00<04:03,  3.74traces/s]\n",
      "Converting traces to Keras learning data:   0%|          | 4/914 [00:01<04:46,  3.17traces/s]\n",
      "Converting traces to Keras learning data:   1%|          | 6/914 [00:01<03:44,  4.04traces/s]\n",
      "Converting traces to Keras learning data:   8%|▊         | 72/914 [00:01<02:26,  5.74traces/s]\n",
      "Converting traces to Keras learning data:   9%|▉         | 86/914 [00:02<01:43,  7.97traces/s]\n",
      "Converting traces to Keras learning data:  12%|█▏        | 112/914 [00:04<01:29,  9.00traces/s]\n",
      "Converting traces to Keras learning data:  18%|█▊        | 163/914 [00:04<01:01, 12.22traces/s]\n",
      "Converting traces to Keras learning data:  24%|██▍       | 219/914 [00:04<00:40, 17.24traces/s]\n",
      "Converting traces to Keras learning data:  28%|██▊       | 252/914 [00:06<00:36, 17.99traces/s]\n",
      "Converting traces to Keras learning data:  36%|███▌      | 331/914 [00:06<00:23, 25.06traces/s]\n",
      "Converting traces to Keras learning data:  41%|████      | 372/914 [00:07<00:18, 29.19traces/s]\n",
      "Converting traces to Keras learning data:  46%|████▌     | 420/914 [00:09<00:17, 27.89traces/s]\n",
      "Converting traces to Keras learning data:  66%|██████▌   | 602/914 [00:10<00:08, 37.80traces/s]\n",
      "Converting traces to Keras learning data:  68%|██████▊   | 617/914 [00:12<00:20, 14.29traces/s]\n",
      "617it [00:12, 14.30it/s]\u001b[A\n",
      "Converting traces to Keras learning data: 100%|██████████| 914/914 [00:12<00:00, 70.53traces/s]\n",
      "Converting traces to Keras validation data:   0%|          | 0/229 [00:00<?, ?traces/s]\n",
      "Converting traces to Keras validation data:   0%|          | 1/229 [00:00<00:32,  7.06traces/s]\n",
      "Converting traces to Keras validation data:   1%|          | 2/229 [00:00<00:33,  6.71traces/s]\n",
      "Converting traces to Keras validation data:   3%|▎         | 8/229 [00:01<00:39,  5.62traces/s]\n",
      "Converting traces to Keras validation data:   7%|▋         | 17/229 [00:02<00:30,  6.93traces/s]\n",
      "Converting traces to Keras validation data:  24%|██▎       | 54/229 [00:02<00:18,  9.64traces/s]\n",
      "Converting traces to Keras validation data:  25%|██▌       | 58/229 [00:02<00:15, 11.21traces/s]\n",
      "Converting traces to Keras validation data:  40%|████      | 92/229 [00:04<00:10, 12.93traces/s]\n",
      "92it [00:04, 12.93it/s]\u001b[A\n",
      "Converting traces to Keras validation data: 100%|██████████| 229/229 [00:04<00:00, 49.53traces/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO: normalize\n",
    "# X = X / float(n_vocab)\n",
    "def wrapped__create_learning_dicts_from_trace(p):\n",
    "    return create_learning_dicts_from_trace(*p)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "# How to understand keras feature shape requirements: https://github.com/keras-team/keras/issues/2045\n",
    "def create_learning_dicts_from_trace(t, sp2_col_start_index, n_sp2_features, pfs_col_start_index, n_pfs_features, target_col_start_index, feature_names):\n",
    "    t_dict = {'x':[], 'y':[]}\n",
    "    # generate one input sequence for every type of variable\n",
    "    # map every single-step batch in a dictionary that will correspond to input layer names!\n",
    "    for i in range(0, len(t)):\n",
    "        batch_dict = {}\n",
    "\n",
    "        # automatically run through all ordinal and categorical features\n",
    "        for col_idx, col in enumerate(feature_names[:sp2_col_start_index]):\n",
    "            input_name = generate_input_name(col)\n",
    "            batch_dict[input_name] = np.array(t.iloc[i, col_idx], dtype=np.float32).reshape([-1,1])\n",
    "\n",
    "        # create batches for sp2 and pfs2 seperately because of their variable encodings\n",
    "        batch_dict[generate_input_name(\"sp2\")] = np.asarray(t.iloc[i, sp2_col_start_index:pfs_col_start_index], dtype=np.float32).reshape([-1,n_sp2_features])\n",
    "        batch_dict[generate_input_name(\"pfs\")] = np.asarray(t.iloc[i, pfs_col_start_index:target_col_start_index], dtype=np.float32).reshape([-1,n_pfs_features])\n",
    "\n",
    "        t_dict['x'].append(batch_dict)\n",
    "    t_dict['y'] = keras.utils.np_utils.to_categorical(t.iloc[:, target_col_start_index:].values.reshape([-1,1,1]))\n",
    "    return t_dict\n",
    "\n",
    "ncores = multiprocessing.cpu_count()\n",
    "ppool = multiprocessing.Pool(ncores)\n",
    "train_traces = []\n",
    "test_traces  = []\n",
    "traces_for_input_dicts = [ (t, sp2_col_start_index, n_sp2_features, pfs_col_start_index, n_pfs_features, target_col_start_index, feature_names) for t in traces ]\n",
    "\n",
    "with tqdm(total=len(traces[:sep_idx]), desc=\"Converting traces to Keras learning data\", unit=\"traces\") as pbar:\n",
    "    for i, _ in tqdm(enumerate(ppool.imap(wrapped__create_learning_dicts_from_trace, traces_for_input_dicts[:sep_idx]))):\n",
    "        pbar.update()\n",
    "        train_traces.append(_)\n",
    "        \n",
    "with tqdm(total=len(traces[sep_idx:]), desc=\"Converting traces to Keras validation data\", unit=\"traces\") as pbar:\n",
    "    for i, _ in tqdm(enumerate(ppool.imap(wrapped__create_learning_dicts_from_trace, traces_for_input_dicts[sep_idx:]))):\n",
    "        pbar.update()\n",
    "        test_traces.append(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_conceptname input_shape=(1, 1) output_shape=(1, 1)\n",
      "input_Specialismcode input_shape=(1, 1) output_shape=(1, 1)\n",
      "input_orggroup input_shape=(1, 1) output_shape=(1, 1)\n",
      "input_Numberofexecutions input_shape=(1, 1) output_shape=(1, 1)\n",
      "input_timetimestamp input_shape=(1, 1) output_shape=(1, 1)\n",
      "embedding_4 input_shape=(1, 1) output_shape=(1, 1, 50)\n",
      "embedding_5 input_shape=(1, 1) output_shape=(1, 1, 13)\n",
      "embedding_6 input_shape=(1, 1) output_shape=(1, 1, 22)\n",
      "reshape_7 input_shape=(1, 1) output_shape=(1, 1, 1)\n",
      "reshape_8 input_shape=(1, 1) output_shape=(1, 1, 1)\n",
      "reshape_9 input_shape=(1, 1, 50) output_shape=(1, 1, 50)\n",
      "reshape_10 input_shape=(1, 1, 13) output_shape=(1, 1, 13)\n",
      "reshape_11 input_shape=(1, 1, 22) output_shape=(1, 1, 22)\n",
      "concatenate_3 input_shape=[(1, 1, 1), (1, 1, 1), (1, 1, 50), (1, 1, 13), (1, 1, 22)] output_shape=(1, 1, 87)\n",
      "lstm_3 input_shape=(1, 1, 87) output_shape=(1, 1, 800)\n",
      "input_sp2 input_shape=(1, 624) output_shape=(1, 624)\n",
      "lstm_4 input_shape=(1, 1, 800) output_shape=(1, 800)\n",
      "reshape_12 input_shape=(1, 624) output_shape=(1, 624)\n",
      "concatenate_4 input_shape=[(1, 800), (1, 624)] output_shape=(1, 1424)\n",
      "dense_join input_shape=(1, 1424) output_shape=(1, 640)\n",
      "dense_final input_shape=(1, 640) output_shape=(1, 625)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "model_inputs = []\n",
    "\n",
    "# forward all ordinal features\n",
    "for ord_var in feature_names[:cat_col_start_index]:\n",
    "    il = Input(batch_shape=(1,1), name=generate_input_name(ord_var))\n",
    "    model = Reshape(target_shape=(1,1,))(il)\n",
    "    model_inputs.append(il)\n",
    "    models.append(model)\n",
    "\n",
    "# create embedding layers for every categorical feature\n",
    "for cat_var in categorical_feature_names :\n",
    "    model = Sequential()\n",
    "    no_of_unique_cat  = len(feature_dict[cat_var]['to_int'])\n",
    "    embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))\n",
    "    vocab  = no_of_unique_cat+1\n",
    "    \n",
    "    il = Input(batch_shape=(1,1), name=generate_input_name(cat_var))    \n",
    "    model = Embedding(vocab, embedding_size)(il)\n",
    "    model = Reshape(target_shape=(1,embedding_size,))(model)\n",
    "    \n",
    "    model_inputs.append(il)\n",
    "    models.append(model)\n",
    "\n",
    "# create input and embedding for sp2/pfs2 features\n",
    "learn_sp2 = True\n",
    "sequence_embedding = None\n",
    "\n",
    "# Can't embed SP2 due to dimensionality with embedding layer, be stringent and do the same for PFS features\n",
    "# instead, mimic the embedding internal architecture and use a Dense/Linear layer\n",
    "if learn_sp2:\n",
    "    il = Input(batch_shape=(1,n_sp2_features), name=generate_input_name(\"sp2\"))\n",
    "    model_inputs.append(il)\n",
    "    sequence_embedding = il\n",
    "    # TODO mimic embedding architecture\n",
    "    sequence_embedding = Reshape(target_shape=(n_sp2_features,))(sequence_embedding)\n",
    "else:\n",
    "    # TODO\n",
    "    pass\n",
    "    \n",
    "# merge the outputs of the embeddings, and everything that belongs to the most recent activity executions\n",
    "main_output = concatenate(models, axis=2)\n",
    "main_output = LSTM(25*32, batch_input_shape=(1,), return_sequences=True, stateful=True)(main_output) # should be multiple of 32 since it trains faster due to np.float32\n",
    "main_output = LSTM(25*32, stateful=True)(main_output) # should be multiple of 32 since it trains faster due to np.float32\n",
    "\n",
    "# after LSTM has learned on the sequence, bring in the SP2/PFS features, like in Shibatas paper\n",
    "main_output = concatenate([main_output, sequence_embedding], axis=1)\n",
    "main_output = Dense(20*32, activation='relu', name='dense_join')(main_output)\n",
    "main_output = Dense(len(feature_dict[\"concept:name\"][\"to_int\"]), activation='sigmoid', name='dense_final')(main_output)\n",
    "\n",
    "full_model = Model(inputs=model_inputs, outputs=[main_output])\n",
    "full_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "for l in full_model.layers:\n",
    "    print(l.name, \"input_shape={}\".format(l.input_shape), \"output_shape={}\".format(l.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam\n"
     ]
    }
   ],
   "source": [
    "print(\"{0}\".format(type(full_model.optimizer).__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the checkpoint\n",
    "# filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "# checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# for t in train_traces:\n",
    "#     full_model.fit(t['x'], t['y'], epochs=10, batch_size=50, callbacks=callbacks_list)\n",
    "#     model.reset_states()\n",
    "\n",
    "for epoch in range(1):\n",
    "    mean_tr_acc = []\n",
    "    mean_tr_loss = []\n",
    "    for t_idx, t in enumerate(train_traces[0:5]):\n",
    "        print(\"Training {0}/{1}\".format(t_idx,len(train_traces)))\n",
    "        for x,y in zip(t['x'],t['y']):\n",
    "            tr_loss = full_model.train_on_batch(x, y)\n",
    "            mean_tr_loss.append(tr_loss)\n",
    "        full_model.reset_states()\n",
    "\n",
    "    print('accuracy training = {}'.format(np.mean(mean_tr_acc)))\n",
    "    print('loss training = {}'.format(np.mean(mean_tr_loss)))\n",
    "    print('___________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = keras.models.load_model(\"my_first_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_idx, t in enumerate(test_traces[0:1]):\n",
    "    for x,y in zip(t['x'],t['y']):\n",
    "        pred_y = full_model.predict(x)\n",
    "        print(\"Predicted: {0} | Actual: {1}\".format(pred_y,y))\n",
    "    full_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = [ np.argmax(p) for p in prediction ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([prediction_index[i] == dataY[i] for i in prediction_index]) / len(prediction_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
