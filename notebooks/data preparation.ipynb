{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import multiprocessing, threading\n",
    "import math\n",
    "import scipy.stats as ss\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from opyenxes.model.XLog import XLog\n",
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "from opyenxes.classification.XEventAttributeClassifier import XEventAttributeClassifier\n",
    "\n",
    "from prefixspan import PrefixSpan\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "data_path = \"../logs/bpic2011.xes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path) as bpic_file:\n",
    "    eventlog = XUniversalParser().parse(bpic_file)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncores = multiprocessing.cpu_count()\n",
    "ntraces = len(eventlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data trace-wise from XES format and enrich with BOS/EOS markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all attributes\n",
    "column_names = []\n",
    "\n",
    "for event in eventlog[0]:\n",
    "    for attribute in event.get_attributes():\n",
    "        column_names.append(attribute)\n",
    "        \n",
    "column_names = set(column_names) # remove duplicates\n",
    "column_names = list(column_names)\n",
    "\n",
    "def create_dataframe_from_trace(t):\n",
    "    df = pd.DataFrame(columns=column_names, index=range(0,len(t)))\n",
    "    for event_idx, event in enumerate(t):\n",
    "        event_attributes = event.get_attributes()\n",
    "        df.iloc[event_idx][\"__case_id\"] = 0\n",
    "\n",
    "        for attribute in event_attributes:\n",
    "            df[attribute].values[event_idx] = event_attributes[attribute].get_value()\n",
    "    \n",
    "    return df\n",
    "\n",
    "ppool = multiprocessing.Pool(ncores)\n",
    "traces = []\n",
    "with tqdm(total=len(eventlog), desc=\"Converting XES traces to Pandas dataframes\", unit=\"traces\") as pbar:\n",
    "    for i, _ in tqdm(enumerate(ppool.imap(create_dataframe_from_trace, eventlog))):\n",
    "        pbar.update()\n",
    "        traces.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del eventlog\n",
    "traces_picklepath = data_path.replace(\".xes\", \"_traces.pickled\")\n",
    "pickle.dump(traces, open(traces_picklepath, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = pickle.load(open(traces_picklepath, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate correlated or unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "        https://stackoverflow.com/questions/46498455/categorical-features-correlation\"\"\"\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "for col_a,col_b in itertools.product(eventlog_df.columns, repeat=2): \n",
    "    candidate = pd.crosstab(eventlog_df[col_a], eventlog_df[col_b]).as_matrix()\n",
    "    print(\"{: >30} {: >30} {: >20}\".format(col_a, col_b, cramers_v(candidate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lifecyle:transition is always \"complete\"\n",
    "# Producer code correlates perfectly with org:group\n",
    "# Activity code correlates perfectly with concept:name\n",
    "for t in traces:\n",
    "    t.drop(columns=[\"lifecycle:transition\", \"Producer code\", \"Activity code\", \"Section\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create standard featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventlog_df = [None] * len(traces)\n",
    "nattr = len(traces[0].columns)\n",
    "bos_df = pd.DataFrame([(\"<bos>\",)*nattr], columns = traces[0].columns)\n",
    "eos_df = pd.DataFrame([(\"<eos>\",)*nattr], columns = traces[0].columns)\n",
    "\n",
    "for i in range(0,len(traces)):\n",
    "    traces[i] = pd.concat([bos_df, traces[i], eos_df], ignore_index=True)\n",
    "\n",
    "eventlog_df = pd.concat(traces, ignore_index=True)\n",
    "# TODO: one-hot encoding still remains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SP2 feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/42636765/how-to-set-all-the-values-of-an-existing-pandas-dataframe-to-zero\n",
    "# This one-hot encodes all entries in concept:name column for later incrementation once it has been seen\n",
    "# sp2_features = pd.get_dummies(eventlog_df[\"concept:name\"], prefix=\"SP2\") # can't use windowed representation here as it might skew distribution of values\n",
    "# eventlog_sp2_df = process_results.copy(deep=True)\n",
    "# sp2_features    = sp2_features.drop(sp2_features.index[sp2_features.index[len(eventlog_sp2_df):]])\n",
    "# assert(len(sp2_features) == len(eventlog_sp2_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through every trace and encode the presence of an activity\n",
    "activity_labels = [ \"SP2_{0}\".format(a) for a in eventlog_df[\"concept:name\"].unique() ]\n",
    "x = None\n",
    "\n",
    "def enrich_trace_with_sp2(t):\n",
    "    sp2_df = pd.DataFrame(columns=activity_labels, index=range(0,len(t)))\n",
    "    \n",
    "    for col in sp2_df.columns: sp2_df[col].values[:] = 0\n",
    "    \n",
    "    sp2_df[\"SP2_<bos>\"].values[0] = 1\n",
    "    for i in range(1,len(t)):\n",
    "        first_activity_name = t[\"concept:name\"].iloc[i]\n",
    "        sp2_df.values[i] = sp2_df.values[i-1]\n",
    "        sp2_df[\"SP2_{0}\".format(first_activity_name)].values[i] = 1\n",
    "    return pd.concat([t, sp2_df], axis=1)\n",
    "\n",
    "ppool = multiprocessing.Pool(ncores)\n",
    "ttraces = []\n",
    "with tqdm(total=len(traces), desc=\"Enriching traces with SP2 features\", unit=\"traces\") as pbar:\n",
    "    for i, _ in tqdm(enumerate(ppool.imap(enrich_trace_with_sp2, traces))):\n",
    "        pbar.update()\n",
    "        ttraces.append(_)\n",
    "        \n",
    "traces = ttraces\n",
    "del ttraces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich with PrefixSpan features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_patterns(pt):\n",
    "    for p in pt:\n",
    "        print(\"Support: {0}%\".format(p[0]))\n",
    "        for n in p[1]:\n",
    "            print(\"    > \", int_to_event[n])\n",
    "        print()\n",
    "        \n",
    "events       = eventlog_df[\"concept:name\"].unique()\n",
    "event_to_int = dict((c, i) for i,c in enumerate(events))\n",
    "int_to_event = dict((i, c) for i,c in enumerate(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefixspan requires an array of arrays with one subarray for every trace\n",
    "encoded_traces = [ t[\"concept:name\"].map(event_to_int).tolist() for t in traces ]\n",
    "prefixspan_traces = PrefixSpan(encoded_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support: 1143%\n",
      "    >  <bos>\n",
      "    >  <eos>\n",
      "\n",
      "Support: 1110%\n",
      "    >  <bos>\n",
      "    >  administratief tarief       - eerste pol\n",
      "    >  <eos>\n",
      "\n",
      "Support: 958%\n",
      "    >  <bos>\n",
      "    >  vervolgconsult poliklinisch\n",
      "    >  <eos>\n",
      "\n",
      "Support: 839%\n",
      "    >  <bos>\n",
      "    >  administratief tarief       - eerste pol\n",
      "    >  vervolgconsult poliklinisch\n",
      "    >  <eos>\n",
      "\n",
      "Support: 804%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 765%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 760%\n",
      "    >  <bos>\n",
      "    >  vervolgconsult poliklinisch\n",
      "    >  vervolgconsult poliklinisch\n",
      "    >  <eos>\n",
      "\n",
      "Support: 729%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  hemoglobine foto-elektrisch\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 723%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  hemoglobine foto-elektrisch\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 723%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  ordertarief\n",
      "    >  administratief tarief       - eerste pol\n",
      "    >  <eos>\n",
      "\n",
      "Support: 709%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  creatinine\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 707%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 707%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  creatinine\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n",
      "Support: 703%\n",
      "    >  <bos>\n",
      "    >  1e consult poliklinisch\n",
      "    >  <eos>\n",
      "\n",
      "Support: 698%\n",
      "    >  <bos>\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  aanname laboratoriumonderzoek\n",
      "    >  hemoglobine foto-elektrisch\n",
      "    >  creatinine\n",
      "    >  ordertarief\n",
      "    >  <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ps_topkc = prefixspan_traces.topk(15, closed=True)\n",
    "print_patterns(ps_topkc)\n",
    "# TODO understand what support means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
