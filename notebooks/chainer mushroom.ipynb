{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer as ch\n",
    "from chainer import datasets\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "import numpy as np\n",
    "mushroomsfile = 'mushrooms.csv'\n",
    "data_array = np.genfromtxt(mushroomsfile, delimiter=',', dtype=str, skip_header=1)\n",
    "\n",
    "for col in range(data_array.shape[1]):\n",
    "    data_array[:, col] = np.unique(data_array[:, col], return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '5', '2', '4', '1', '6', '1', '0', '1', '4', '0', '3', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '3', '5'],\n",
       "       ['0', '5', '2', '9', '1', '0', '1', '0', '0', '4', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '3', '2', '1'],\n",
       "       ['0', '0', '2', '8', '1', '3', '1', '0', '0', '5', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '3', '2', '3'],\n",
       "       ['1', '5', '3', '8', '1', '6', '1', '0', '1', '5', '0', '3', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '3', '5'],\n",
       "       ['0', '5', '2', '3', '0', '5', '1', '1', '0', '4', '1', '3', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '0', '3', '0', '1'],\n",
       "       ['0', '5', '3', '9', '1', '0', '1', '0', '0', '5', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '2', '1'],\n",
       "       ['0', '0', '2', '8', '1', '0', '1', '0', '0', '2', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '2', '3'],\n",
       "       ['0', '0', '3', '8', '1', '3', '1', '0', '0', '5', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '3', '3', '3'],\n",
       "       ['1', '5', '3', '8', '1', '6', '1', '0', '1', '7', '0', '3', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '4', '1'],\n",
       "       ['0', '0', '2', '9', '1', '0', '1', '0', '0', '2', '0', '2', '2',\n",
       "        '2', '7', '7', '0', '2', '1', '4', '2', '3', '3']], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_array[:, 1:].astype(np.float32) #  extract all columns but the first from all rows\n",
    "Y = data_array[:, 0].astype(np.int32)[:, None] # extract only the first column and put each element into an array of its own\n",
    "train, test = datasets.split_dataset_random(\n",
    "    datasets.TupleDataset(X, Y), int(data_array.shape[0] * .7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix.wolff2/.local/lib/python3.6/site-packages/chainer/training/extensions/plot_report.py:25: UserWarning: matplotlib is not installed on your environment, so nothing will be plotted at this time. Please install matplotlib to plot figures.\n",
      "\n",
      "  $ pip install matplotlib\n",
      "\n",
      "  warnings.warn('matplotlib is not installed on your environment, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           0.557323    0.48885               0.729123       0.781684                  0.251866      \n",
      "\u001b[J2           0.434331    0.435051              0.828772       0.818632                  0.475131      \n",
      "\u001b[J3           0.390184    0.406244              0.845439       0.841832                  0.740202      \n",
      "\u001b[J4           0.356114    0.371526              0.862982       0.851432                  0.976747      \n",
      "\u001b[J5           0.331505    0.351207              0.873684       0.868232                  1.22832       \n"
     ]
    }
   ],
   "source": [
    "train_iter = ch.iterators.SerialIterator(train, 100)\n",
    "test_iter = ch.iterators.SerialIterator(\n",
    "    test, 100, repeat=False, shuffle=False)\n",
    "\n",
    "\n",
    "# Network definition\n",
    "def MLP(n_units, n_out):\n",
    "    layer = ch.Sequential(L.Linear(n_units), F.relu)\n",
    "    model = layer.repeat(2)\n",
    "    model.append(L.Linear(n_out))\n",
    "\n",
    "    return model\n",
    "\n",
    "    def __call__(self,x):\n",
    "        print(x)\n",
    "        return model(x)\n",
    "\n",
    "\n",
    "model = L.Classifier(\n",
    "    MLP(44, 1), lossfun=F.sigmoid_cross_entropy, accfun=F.binary_accuracy)\n",
    "\n",
    "# Setup an optimizer\n",
    "optimizer = ch.optimizers.SGD().setup(model)\n",
    "\n",
    "# Create the updater, using the optimizer\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "\n",
    "# Set up a trainer\n",
    "trainer = training.Trainer(updater, (1, 'epoch'), out='result')\n",
    "# Evaluate the model with the test dataset for each epoch\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "\n",
    "# Dump a computational graph from 'loss' variable at the first iteration\n",
    "# The \"main\" refers to the target link of the \"main\" optimizer.\n",
    "trainer.extend(extensions.dump_graph('main/loss'))\n",
    "\n",
    "trainer.extend(extensions.snapshot(), trigger=(2, 'epoch'))\n",
    "\n",
    "# Write a log of evaluation statistics for each epoch\n",
    "trainer.extend(extensions.LogReport())\n",
    "\n",
    "# Save two plot images to the result dir\n",
    "if extensions.PlotReport.available():\n",
    "    trainer.extend(\n",
    "        extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
    "                              'epoch', file_name='loss.png'))\n",
    "    trainer.extend(\n",
    "        extensions.PlotReport(\n",
    "            ['main/accuracy', 'validation/main/accuracy'],\n",
    "            'epoch', file_name='accuracy.png'))\n",
    "\n",
    "# Print selected entries of the log to stdout\n",
    "trainer.extend(extensions.PrintReport(\n",
    "    ['epoch', 'main/loss', 'validation/main/loss',\n",
    "     'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
    "\n",
    "#  Run the training\n",
    "trainer.run()\n",
    "\n",
    "# x, t = test[np.random.randint(len(test))]\n",
    "\n",
    "# predict = model.predictor(x[None]).data\n",
    "# predict = predict[0][0]\n",
    "\n",
    "# if predict >= 0:\n",
    "#     print('Predicted Poisonous, Actual ' + ['Edible', 'Poisonous'][t[0]])\n",
    "# else:\n",
    "#     print('Predicted Edible, Actual ' + ['Edible', 'Poisonous'][t[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
