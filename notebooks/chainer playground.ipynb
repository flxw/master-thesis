{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer.backends import cuda\n",
    "from chainer import Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "import random\n",
    "\n",
    "from opyenxes.model.XLog import XLog\n",
    "from opyenxes.data_in.XUniversalParser import XUniversalParser\n",
    "from opyenxes.classification.XEventAttributeClassifier import XEventAttributeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown extension: http://www.xes-standard.org/meta_time.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_life.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_org.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_concept.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_3TU.xesext\n",
      "Unknown extension: http://www.xes-standard.org/meta_general.xesext\n"
     ]
    }
   ],
   "source": [
    "bpic_2011_path = \"../logs/bpic2011.xes\"\n",
    "\n",
    "with open(bpic_2011_path) as bpic2011_file:\n",
    "    bpic2011_rlog = XUniversalParser().parse(bpic2011_file)\n",
    "\n",
    "bpic2011_log = bpic2011_rlog[0] # the rest of this array is empty anyway as len(bpic2011_rlog) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_traces = [[ ev.get_attributes()[\"concept:name\"].get_value() for ev in trace ] for trace in bpic2011_log ]\n",
    "event_traces = [ ['<bos>'] + l + ['<eos>'] for l in event_traces ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventDataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, event_traces, windowsize):\n",
    "        self.data = [ w for w in self.window_features(event_traces, windowsize) ]\n",
    "    \n",
    "    def window_features(self,traces,windowsize):\n",
    "        for trace in traces:\n",
    "            for event_i in range(0, len(trace)-windowsize+1):\n",
    "                yield(trace[event_i:event_i+windowsize])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_example(self, i):\n",
    "        example = self.data[i]\n",
    "        return tuple(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(event_traces)\n",
    "test_traces  = event_traces[:int(.8*len(event_traces))]\n",
    "train_traces = event_traces[int(.8*len(event_traces)):]\n",
    "test  = EventDataset(event_traces, 4)\n",
    "train = EventDataset(event_traces, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x7f1875d03588>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(Chain):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.embed = L.EmbedID(1000, 100)  # word embedding\n",
    "            self.mid = L.LSTM(100, 50)  # the first LSTM layer\n",
    "            self.out = L.Linear(50, 1000)  # the feed-forward output layer\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mid.reset_state()\n",
    "\n",
    "    def __call__(self, cur_word):\n",
    "        # Given the current word ID, predict the next word.\n",
    "        x = self.embed(cur_word)\n",
    "        h = self.mid(x)\n",
    "        y = self.out(h)\n",
    "        return y\n",
    "\n",
    "rnn = RNN()\n",
    "model = L.Classifier(rnn)\n",
    "optimizer = optimizers.SGD()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading from http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
